---
title: "Project 2"
author: "Lukas Leindals"
date: "15/1/2020"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# set seed
set.seed(-2000)

# packages
library(ggplot2)
library(magrittr)
```



# Data

```{r echo=FALSE}
data_fos <- get(load("fosfor_data.Rdata")) %>% 
  data.frame() %>% 
  dplyr::mutate(location = as.factor(location))
data_fos

```

## Summaries

```{r}
cat("Structure")
str(data_fos)
cat("Summary")
summary(data_fos)
cat("Data")
data_fos

# nas <- which(is.na(data_fos$yield)) 
# data_fos[unique(c(nas, nas+1, nas-1)), ]

#xtable::xtable(summary(data_fos, maxsum = 9)) #converts to latex

      
```

## Handle NA's

Uses KNN imputation and looks at the k nearest neighbors, the missing value is then replaced with the average of the values for the nearest neighbors

```{r}
data_fos <- DMwR::knnImputation(data_fos,k=2, meth = "Median")
```

## grouped data set

groups the data, so that there is only one yield for each combination of location, DGT and olsenP, which is the mean. THis is done as these three factors are strongly dependent of each other.

```{r}
data_grouped <- data_fos %>% dplyr::group_by(location, DGT, olsenP) %>% dplyr::summarise_each(mean)
data_grouped

ggplot(tidyr::gather(data_grouped, "key", "value", -c(location, yield)), aes(value, yield, col = location)) +
  geom_point() +
  facet_wrap("key", scales = "free")
```


## Plots

```{r}
GGally::ggpairs(data_fos, columns = c("DGT", "olsenP", "yield"))


#par(mfrow = c(3,1))
boxplot(yield ~location, data = data_fos)
boxplot(DGT ~ location, data = data_fos)
boxplot(olsenP ~ location, data = data_fos)

data_fos %>% tidyr::gather("key", "value", -location) %>% dplyr::filter(key == "yield") %>% ggplot(aes(x = location, y = value, fill = key)) + geom_boxplot() 
par(mfrow = c(1,2))
plot(data = data_fos , yield ~ olsenP)
plot(data = data_fos , yield ~ DGT)
```


# Models

## ANOVA

```{r}
lm1 <- lm(data = data_fos, formula = yield ~ DGT)
anova(lm1)
summary(lm1)


lm2 <- lm(data = data_fos, formula = yield ~ olsenP)
anova(lm2)
summary(lm2)

lm3 <- lm(data = data_fos, formula = yield ~ location)
anova(lm3)
summary(lm3)


phos.model.DGT <- nls(yield ~ alfa * DGT/(beta + DGT) , data = data_fos,
start = list(alfa = 90 , beta = 1))

phos.model.olsenP <- nls(yield ~ alfa * olsenP/(beta + olsenP) , data = data_fos,
start = list(alfa = 90 , beta = 1))



summary(phos.model.DGT)
summary(phos.model.olsenP)


par(mfrow=(c(1,2)))
alfa1 <- coef(phos.model.DGT)[1]
beta1 <- coef(phos.model.DGT)[2]
alfa2 <- coef(phos.model.olsenP)[1]
beta2 <- coef(phos.model.olsenP)[2]
plot(data = data_fos , yield ~ DGT)
lines(x<-c(1:200),(alfa1 * x )/(beta1 + x),col='red')
plot(data = data_fos , yield ~ olsenP)
lines(x<-c(1:200),(alfa2 * x )/(beta2 + x),col='red')
```

```{r}
lm3 <- lm(data = data_fos, formula = DGT ~ location)
summary(lm3)
cor(data_fos$location, data_fos$DGT)
```


# Predictions - Test errorrate med leave one out cross validation
```{r}


data_CV <- data_fos

N <- nrow(data_CV)
s <- sample(N)
K_fold <- N


accuracy <- c()
random_index <- split(sample(c(1:N),N), c(1:K_fold))
loss <- c()
for (i in c(1:K_fold)){
  f <- c(1:K_fold)[-i]
  train_index <- Reduce(c,random_index[f])
  test_index <- Reduce(c,random_index[i])

  train_set <- data_CV[train_index,]
  test_set <- data_CV[test_index,]
  model_cv_DGT <- phos.model.DGT_perm <- nls(yield ~ alfa * DGT/(beta + DGT) , data = train_set,
                        start = list(alfa = 90 , beta = 1))
  
  model_cv_olsenP <- phos.model.DGT_perm <- nls(yield ~ alfa * olsenP/(beta + olsenP) , data = train_set,
                        start = list(alfa = 90 , beta = 1))
  
  pred_DGT <- predict(model_cv_DGT, test_set)
  pred_olsenP <- predict(model_cv_olsenP, test_set)
  
  error_DGT <- sum((test_set$yield - pred_DGT)^2)
  error_olsenP <- sum((test_set$yield - pred_olsenP)^2)
  loss <- rbind(loss,c(error_DGT, error_olsenP))
  
}
Z <- loss[,1] - loss[,2]
t.test(Z)
t.test(loss[,1], loss[,2], paired =T)
qqnorm(Z)
qqline(Z)


```

# Bootstrap - Difference in performance with Michaelis Menten fitted to DGT vs olsenP
Non parametric bootstrapping. Sampler fra forskel i loss af de to modeller. Udregner mean af disse forskelle og bestemmer konfidens intervaller.
```{r}
z_bootstrap <- apply( replicate(10000, sample(Z, replace = T)), 2, mean)
hist(z_bootstrap)
alfa <- 0.05
quantile(z_bootstrap, c(alfa/2,1-alfa/2))
```

# Rank Sum Test - Difference in performance with Michaelis Menten fitted to DGT vs olsenP
Concatenates loss af DGT og olsenP. Bestemmers størrelseordenen af denne vektor og finder rank sum for DGT.
Derefter laves permutationer af vektor med 1-72 og rank sum af de 36 første bestemmes og sammenlignes med rank sum for DGT
```{r}
Z_RST <- order(c(loss[,1], loss[,2]))
DGT_RS <- sum(Z_RST[1:36])
RST <- c()
for (i in 1:1000){
  RST_sample <- sample(72)
  RST <- c(RST,sum(RST_sample[1:36]))
}
p_val <- 2*mean(DGT_RS>RST)
p_val
hist(RST)
Z_RST
```



# Permutation test

```{r}
n <- 500
results_DGT <- c()
results_olsenP <- c()
for (i in 1:n){
  permutation <- sample(nrow(data_fos))
  
  phos.model.DGT_perm <- nls(yield[permutation] ~ alfa * DGT/(beta + DGT) , data = data_fos,
                        start = list(alfa = 90 , beta = 1))

  phos.model.olsenP_perm <- nls(yield[permutation] ~ alfa * olsenP/(beta + olsenP) , data = data_fos,
                            start = list(alfa = 90 , beta = 1))
  
  results_DGT <- rbind(results_DGT, coef(phos.model.DGT_perm))
  results_olsenP <- rbind(results_olsenP, coef(phos.model.olsenP_perm))
}
sum(beta1 < results_DGT[,2])
mean(results_DGT[,2])
alfa1
beta1
```