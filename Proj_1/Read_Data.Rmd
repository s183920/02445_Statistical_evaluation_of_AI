---
title: "Project1"
author: "Peter"
date: "1/12/2020"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# load packages

library(zoo)
'library(magrittr)
library(reticulate)'
```





# Indlæser data
Indlæser data til en 'bred' matrix med 302 kolonner, en med person, en med repetition og 300 med X Y Z.
```{r}
data <- get(load("armdata.Rdata"))[5][[1]]
pers1 <- data[[1]][[2]]
person <- 10
rep <- 10
x <- c()
y <- c()
z <- c()
for (p in 1:person){
  for (r in 1:rep){
    
    longitude <- data[[p]][[r]][,1]
    x <- cbind(x,data[[p]][[r]][,1])
  }
}
for (p in 1:person){
  for (r in 1:rep){
    
    transversal <- data[[p]][[r]][,2]
    y <- cbind(y,data[[p]][[r]][,2])
  }
}
for (p in 1:person){
  for (r in 1:rep){
    
    vertical <- data[[p]][[r]][,3]
    z <- cbind(z,data[[p]][[r]][,3])
  }
}

x <- t(na.locf(x, fromLast = T))
y <- t(na.locf(y, fromLast = T))
z <- t(na.locf(z, fromLast = T))

colnames <- c( paste0("x_", 1:100),paste0("y_", 1:100),paste0("z_", 1:100))
persons <- c(rep("person1", 10),rep("person2", 10),rep("person3", 10),rep("person4", 10),rep("person5", 10),rep("person6", 10),rep("person7", 10),rep("person8", 10),rep("person9", 10),rep("person10", 10))
reps <- rep(1:10,10)

data_wide <- as.data.frame(cbind(x,y,z), row.names = 1:100)
names(data_wide) <- colnames

data_wide <- cbind(persons,reps,data_wide)
head(data_wide)
```

## Alternative Data Load
Indlæser data som en 'lang' matrix med 7 kolonner - En med experiment, en med person, en med repition, en med tid og tre med X Y Z.
```{r}
data <- get(load("armdata.Rdata"))
persons <- 10
repetitions <- 10
experiements <- 16
time <- 100
data_long <- c()
for (i in 1:experiements){
  print(i)
  exp <- data[i][[1]]

  for (j in 1:persons){
    pers <- exp[[j]]
    
    for (k in 1:repetitions){
      rep <- pers[[k]]
      
      data_long <- rbind(data_long, (cbind(rep(i,100),rep(j,100), rep(k,100), c(1:100) , rep)))
      
    }
    
  }

}

data_long <- as.data.frame(data_long)
names(data_long) <- c("Experiment", "Person", "Repetition", "Time", "X", "Y", "Z")
data_long$Experiment <- as.factor(data_long$Experiment)
data_long$Person <- as.factor(data_long$Person)
data_long$Repetition <- as.factor(data_long$Repetition)
data_long$Time <- as.factor(data_long$Time)

data_exp5 <- subset(data_long, Experiment == 5)
data_exp5
which(is.na(data_exp5), arr.ind = T)



data_exp5 <- na.locf(data_exp5)
write.csv(data_exp5, "Data_exp5.csv")
```





## Rename data

```{r}
names(data_wide) <- paste0("person_", 1:10)
 
for (per in c(1:length(data))) {
  names(data[[per]]) <- paste0("repetion_", 1:10)
  for (rep in c(1:length(data[[per]]))) {
    colnames(data[[per]][[rep]]) <- c("x", "y", "z")
  }
}
```

## Plots

```{r}
library(rgl)
#cbind(x,y,z)
plot3d(data$person_1$repetion_1, type = 'p', col = heat.colors(1000), lwd = 2, xlab = 'x', ylab = 'y', zlab = 'z')

```


# Standardization

```{r}
data_wide[colnames] <- scale(data_wide[colnames])

#str(data_wide[,-c(1,2)])
pca <- prcomp(x = data_wide[,-c(1,2)], scale. = T, center = T)
summary(pca)

plot(pca$x, col = data_wide$persons)
```
# PCA - test

# Machine learning

Methods

```{r}
names(getModelInfo())
library(ggplot2)

w <- sort(rep(1:10,10))
svd <- svd(data_wide[3:302])
PC <- as.matrix(data_wide[3:302]) %*% svd$v
ggplot(data = as.data.frame(PC), aes(x = V1, y = V2, col = as.factor(w))) + geom_point()
svd$d
```














# Cross - Validation KNN

```{r}
library(class)
data_KNN <- data_exp5
s <- sample(10000)
nrow(data_exp5)
N <- nrow(data_KNN)
K_fold <- 50
K <- c(1:20)
errors <- matrix(rep(NA, K_fold * length(K)), nrow = K_fold)


random_index <- split(sample(c(1:N),N), c(1:K_fold))
 
for (i in c(1:K_fold)){
  print(i)
  f <- c(1:K_fold)[-i]
  train_index <- Reduce(c,random_index[f])
  test_index <- Reduce(c,random_index[i])

  train_set <- data_exp5[train_index,]
  test_set <- data_exp5[test_index,]
  
  for (k in K){
    
    E <- mean(knn(train_set[,c(3:7)], test_set[,c(3:7)], train_set$Person, k = k) != test_set$Person)
    errors[i,k] <- E
    
    
  }
  

}

#KNN
apply(errors,2,mean)
```


```{r}



library(class)
set.seed(235)

ind <- sample(100)
knn_data <- data_wide[, -c(1,2)]

train_set <- knn_data[ind[1:80],]
test_set <- knn_data[ind[81:100],]
train_labels <- data_wide$persons[ind[1:80]]
test_labels <- data_wide$persons[ind[81:100]]

#knn_data <- data_wide[, -c(1,2)]
mean(knn(train_set, test_set, train_labels, k = 10) == test_labels)
m <- apply(errors, 2, mean)
which.min(m)
m
plot(m)

```


```










# Gaussian Mixture Model

```{r}
library(mclust, quietly=TRUE)

## leave one out

```{r}
library(caret)
data_wide[, -c(1,2)] <- scale(data_wide[, -c(1,2)])

trControl <- trainControl(method  = "LOOCV",
                          number  = 5)

fit <- train(persons ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:10),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = data_wide[,-2])

fit
G <- Mclust(data_wide[colnames], G = 10)
G$classification
G$classification
summary(G)
G$classification
```











# Neural Network
```{r}
library(neuralnet)
```


```{r}
model <- neuralnet(data = data_wide[,-2], formula = rownames ~ ., hidden = 5)
summary(model)
plot(model)
model$result.matrix
model$model.list
predictions <- predict(model, data_wide[colnames])
apply(predictions, 1, which.max)
```
ANN - Cross validation

```{r}
data_NN <- data_exp5[,-1]
data_NN$Time <- as.numeric(data_NN$Time)

N <- nrow(data_NN)
K_fold <- 10
hidden <- c(1)
random_index <- split(sample(c(1:N),N), c(1:K_fold))
errors <- matrix(rep(NA,K_fold*length(hidden)), nrow = length(hidden))

true_class <- data_NN$Person

accuracy <- rep(NA, K_fold)

for (i in c(1:K_fold)){
    print(i)
    f <- c(1:K_fold)[-i]
    train_index <- Reduce(c,random_index[f])
    test_index <- Reduce(c,random_index[i])
    train_set <- data_NN[train_index,]
    test_set <- data_NN[test_index,]
      
    print(nrow(train_set))
    print(sum(is.na(train_set)))
    model <- neuralnet(data = train_set, formula = Person ~   X + Y + Z, hidden = 1,                                          linear.output = F, act.fct = "logistic")
    print(i)
    results <- compute(model, test_set[,-2])
    acc <- mean(apply(results$net.result, 1, which.max) == true_class[test_index])
    accuracy[i] <- acc
}
mean(accuracy)
model <- neuralnet(data = train_set[,-2], formula = Person ~ X + Y + Z, hidden = 1,                                          linear.output = F, act.fct = "logistic", rep = 10)
train_set[,-2]
summary(model)
```


```{r}
model <- neuralnet(data = data_wide[,-2][train_index,], formula = rownames ~ ., hidden = 10, linear.output = F, act.fct = "logistic")
summary(model)
model$net.result
nrow(model$net.result[[1]])
results <- compute(model, data_wide[colnames][test_index,])
apply(results$net.result,1, which.max)
data_wide[]
```


```{r}
```








# Punkt 2 - Statistik
Test om der er signifikant effekt af 'experiment' på de resulterende kurver.
```{r}
model_anova <- lm(data = data_long, formula = Y ~ Experiment * Person)
summary(model_anova)
anova(model_anova)
```


