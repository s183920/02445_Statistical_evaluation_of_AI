---
title: "Project1"
author: "Peter"
date: "1/12/2020"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# load packages

library(zoo)
'library(magrittr)
library(reticulate)'
```





# Indl√¶ser data
```{r}
data <- get(load("armdata.Rdata"))[5][[1]]
pers1 <- data[[1]][[2]]
person <- 10
rep <- 10
x <- c()
y <- c()
z <- c()
for (p in 1:person){
  for (r in 1:rep){
    
    longitude <- data[[p]][[r]][,1]
    x <- cbind(x,data[[p]][[r]][,1])
  }
}
for (p in 1:person){
  for (r in 1:rep){
    
    transversal <- data[[p]][[r]][,2]
    y <- cbind(y,data[[p]][[r]][,2])
  }
}
for (p in 1:person){
  for (r in 1:rep){
    
    vertical <- data[[p]][[r]][,3]
    z <- cbind(z,data[[p]][[r]][,3])
  }
}

x <- t(na.locf(x, fromLast = T))
y <- t(na.locf(y, fromLast = T))
z <- t(na.locf(z, fromLast = T))

colnames <- c( paste0("x_", 1:100),paste0("y_", 1:100),paste0("z_", 1:100))
persons <- c(rep("person1", 10),rep("person2", 10),rep("person3", 10),rep("person4", 10),rep("person5", 10),rep("person6", 10),rep("person7", 10),rep("person8", 10),rep("person9", 10),rep("person10", 10))
reps <- rep(1:10,10)

data_wide <- as.data.frame(cbind(x,y,z), row.names = 1:100)
names(data_wide) <- colnames

data_wide <- cbind(persons,reps,data_wide)
head(data_wide)
```
## Alternative Data Load
```{r}
data <- get(load("armdata.Rdata"))
persons <- 10
repetitions <- 10
experiements <- 16
time <- 100
data_long <- c()
for (i in 1:experiements){
  print(i)
  exp <- data[i][[1]]

  for (j in 1:persons){
    pers <- exp[[j]]
    
    for (k in 1:repetitions){
      rep <- pers[[k]]
      
      data_long <- rbind(data_long, (cbind(rep(i,100),rep(j,100), rep(k,100), c(1:100) , rep)))
      
    }
    
  }

}

data_long <- as.data.frame(data_long)
names(data_long) <- c("Experiment", "Person", "Repetition", "Time", "X", "Y", "Z")
data_long$Experiment <- as.factor(data_long$Experiment)
data_long$Person <- as.factor(data_long$Person)
data_long$Repetition <- as.factor(data_long$Repetition)
data_long$Time <- as.factor(data_long$Time)

data_exp5 <- subset(data_long, Experiment == 5)
data_exp5
which(is.na(data_exp5), arr.ind = T)

data_exp5[8001,]

data_exp5 <- na.locf(data_exp5)

```





## Rename data

```{r}
names(data) <- paste0("person_", 1:10)
 
for (per in c(1:length(data))) {
  names(data[[per]]) <- paste0("repetion_", 1:10)
  for (rep in c(1:length(data[[per]]))) {
    colnames(data[[per]][[rep]]) <- c("x", "y", "z")
  }
}
```

## Plots

```{r}
library(rgl)
#cbind(x,y,z)
plot3d(data$person_1$repetion_1, type = 'p', col = heat.colors(1000), lwd = 2, xlab = 'x', ylab = 'y', zlab = 'z')

```


# Standardization

```{r}
data_wide[colnames] <- scale(data_wide[colnames])

#str(data_wide[,-c(1,2)])
pca <- prcomp(x = data_wide[,-c(1,2)], scale. = T, center = T)
summary(pca)

plot(pca$x, col = data_wide$persons)
```
# PCA - test

# Machine learning

Methods

```{r}
names(getModelInfo())
library(ggplot2)

w <- sort(rep(1:10,10))
svd <- svd(data_wide[3:302])
PC <- as.matrix(data_wide[3:302]) %*% svd$v
ggplot(data = as.data.frame(PC), aes(x = V1, y = V2, col = as.factor(w))) + geom_point()
svd$d
```

# Cross - Validation KNN

```{r}
library(class)
s <- sample(10000)
nrow(data_exp5)
N <- 100
K <- c(1:20)
errors <- matrix(rep(NA, N*length(K)), nrow = N)
for (i in 1:N){
  print(paste0("Fold_", i))
  train_index <- s[-i]
  test_index <- s[i]
  train_set <- data_exp5[train_index,]
  test_set <- data_exp5[test_index,]
  
  for (k in K){
    
    E <- sum(knn(train_set[,c(3:6)], test_set[,c(3:6)], train_set$Person, k = k) != test_set$Person)
    errors[i,k] <- E
    
    
  }
  
  
  
  
}

#KNN

```{r}
library(class)
set.seed(235)

ind <- sample(100)
knn_data <- data_wide[, -c(1,2)]

train_set <- knn_data[ind[1:80],]
test_set <- knn_data[ind[81:100],]
train_labels <- data_wide$persons[ind[1:80]]
test_labels <- data_wide$persons[ind[81:100]]

#knn_data <- data_wide[, -c(1,2)]
mean(knn(train_set, test_set, train_labels, k = 10) == test_labels)

```
m <- apply(errors, 2, mean)
which.min(m)
m
plot(m)

```

# Gaussian Mixture Model

```{r}
library(mclust, quietly=TRUE)

## leave one out

```{r}
library(caret)
data_wide[, -c(1,2)] <- scale(data_wide[, -c(1,2)])

trControl <- trainControl(method  = "LOOCV",
                          number  = 5)

fit <- train(persons ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:10),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = data_wide[,-2])

fit
G <- Mclust(data_wide[colnames], G = 10)
G$classification
G$classification
summary(G)
G$classification
```

# Neural Network
```{r}
library(neuralnet)

model <- neuralnet(data = data_wide[,-2], formula = rownames ~ ., hidden = 5)
summary(model)
plot(model)
model$result.matrix
model$model.list
predictions <- predict(model, data_wide[colnames])
apply(predictions, 1, which.max)


N <- 100
K_fold <- 100

random_index <- split(sample(c(1:N),N), c(1:K_fold))
errors <- matrix(rep(0,K_fold*n), nrow = n)
true_class <- sort(rep(1:10,10))
true_class
accuracy <- rep(NA, K_fold)
for (i in c(1:K_fold)){
    f <- c(1:K_fold)[-i]
    train_index <- Reduce(c,random_index[f])
    test_index <- Reduce(c,random_index[i])
    
    model <- neuralnet(data = data_wide[,-2][train_index,], formula = rownames ~ ., hidden = 20, linear.output = F, act.fct = "logistic")
    results <- compute(model, data_wide[colnames][test_index,])
    print(apply(results$net.result, 1, which.max))
    acc <- mean(apply(results$net.result, 1, which.max) == true_class[test_index])
    accuracy[i] <- acc
}
mean(accuracy)

model <- neuralnet(data = data_wide[,-2][train_index,], formula = rownames ~ ., hidden = 10, linear.output = F, act.fct = "logistic")
summary(model)
model$net.result
nrow(model$net.result[[1]])
results <- compute(model, data_wide[colnames][test_index,])
apply(results$net.result,1, which.max)
data_wide[]
```

```{r}
data[[1]][[1]]
```




