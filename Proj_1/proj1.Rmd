---
title: "Project1"
author: "Peter"
date: "1/12/2020"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# load packages

library(zoo)
library(magrittr)

```





# Indlæser data

```{r dataload}
# data <- get(load("armdata.Rdata"))

```

Rename data

```{r rename data}
# names(data) <- paste0("experiment_", 1:16)
# 
# for (expe in c(1:length(data))){
#   names(data[[expe]]) <- paste0("person_", 1:10)
#   for (per in c(1:length(data[[expe]]))) {
#     names(data[[expe]][[per]]) <- paste0("repetion_", 1:10)
#     for (rep in c(1:length(data[[expe]][[per]]))) {
#       colnames(data[[expe]][[per]][[rep]]) <- c("x", "y", "z")
#     }
#   }
# }


```

## Data long

```{r data long}
# data_long <- as.data.frame(data)
# 
# data_long <- data_long %>% 
#   tidyr::gather(key = "col_name", value = "value") %>% 
#   tidyr::separate(col_name, c("experiment", "person", "repetition", "direction"), sep = "\\.") %>% 
#   dplyr::mutate(experiment = stringr::str_remove(string = experiment, pattern = ".*\\_")) %>% 
#   dplyr::mutate(person = stringr::str_remove(string = person, pattern = ".*\\_")) %>%
#   dplyr::mutate(repetition = stringr::str_remove(string = repetition, pattern = ".*\\_")) %>%
#   dplyr::mutate(direction = direction) %>%
#   dplyr::mutate(time = rep(1:100, dim(data_long)[2]))
# 
# cat("Head of data long")
# head(data_long)
# cat("Dimensions of data long")
# dim(data_long)

```

## Data wide

Indlæser data til en 'bred' matrix med 302 kolonner, en med person, en med repetition og 300 med X Y Z.

!!! Data is sorted in a weird way

```{r}


# data_long %>%
#   dplyr::mutate("time_temp" = time, "direction_temp" = direction) %>%
#   tidyr::unite(position, direction, time, sep = "_") %>%
#   tidyr::spread(position, value) %>%
#   dplyr::arrange(as.numeric(experiment), as.numeric(person), as.numeric(repetition)) %>% 
#   dplyr::group_by(experiment)
# 
# cat("Head of data long")
# head(data_wide)
# cat("Dimensions of data long")
# dim(data_wide)
# 
# data_wide[gtools::mixedorder(data_wide$repetition,data_wide$person),]
# 
# gtools::mixedorder(data_wide$repetition,data_wide$person)
# gtools::mixedorder(data_wide$repetition)
```

## Data for eexperiment 5

```{r}
# data_long_exp5 <- data_long %>% dplyr::filter(experiment == 5)
# data_wide_exp5 <- data_wide %>% dplyr::filter(experiment == "experiment_5") %>% dplyr::select(-experiment)
# 
# data_wide

```



Indlæser data til en 'bred' matrix med 302 kolonner, en med person, en med repetition og 300 med X Y Z.
```{r}
data <- get(load("armdata.Rdata"))[5][[1]]
pers1 <- data[[1]][[2]]
person <- 10
rep <- 10
x <- c()
y <- c()
z <- c()
for (p in 1:person){
  for (r in 1:rep){

    longitude <- data[[p]][[r]][,1]
    x <- cbind(x,data[[p]][[r]][,1])
  }
}
for (p in 1:person){
  for (r in 1:rep){

    transversal <- data[[p]][[r]][,2]
    y <- cbind(y,data[[p]][[r]][,2])
  }
}
for (p in 1:person){
  for (r in 1:rep){

    vertical <- data[[p]][[r]][,3]
    z <- cbind(z,data[[p]][[r]][,3])
  }
}

x <- t(na.locf(x, fromLast = T))
y <- t(na.locf(y, fromLast = T))
z <- t(na.locf(z, fromLast = T))

colnames <- c( paste0("x_", 1:100),paste0("y_", 1:100),paste0("z_", 1:100))
persons <- c(rep("person1", 10),rep("person2", 10),rep("person3", 10),rep("person4", 10),rep("person5", 10),rep("person6", 10),rep("person7", 10),rep("person8", 10),rep("person9", 10),rep("person10", 10))
reps <- rep(1:10,10)

data_wide <- as.data.frame(cbind(x,y,z), row.names = 1:100)
names(data_wide) <- colnames

data_wide <- cbind(persons,reps,data_wide)
head(data_wide)
```

```{r}
#tidyr::unnest(as.data.frame(data_exp5_named))
```


### Rename data

```{r}
names(data) <- paste0("person_", 1:10)
 
for (per in c(1:length(data))) {
  names(data[[per]]) <- paste0("repetion_", 1:10)
  for (rep in c(1:length(data[[per]]))) {
    colnames(data[[per]][[rep]]) <- c("x", "y", "z")
  }
}

data_exp5_named <- data
```


## Data long
Indlæser data som en 'lang' matrix med 7 kolonner - En med experiment, en med person, en med repition, en med tid og tre med X Y Z.
```{r}
data <- get(load("armdata.Rdata"))
persons <- 10
repetitions <- 10
experiements <- 16
time <- 100
data_long <- c()
for (i in 1:experiements){
  print(i)
  exp <- data[i][[1]]

  for (j in 1:persons){
    pers <- exp[[j]]
    
    for (k in 1:repetitions){
      rep <- pers[[k]]
      
      data_long <- rbind(data_long, (cbind(rep(i,100),rep(j,100), rep(k,100), c(1:100) , rep)))
      
    }
    
  }

}

data_long <- as.data.frame(data_long)
names(data_long) <- c("Experiment", "Person", "Repetition", "Time", "X", "Y", "Z")
data_long$Experiment <- as.factor(data_long$Experiment)
data_long$Person <- as.factor(data_long$Person)
data_long$Repetition <- as.factor(data_long$Repetition)
data_long$Time <- as.factor(data_long$Time)

data_exp5 <- subset(data_long, Experiment == 5)
data_exp5
which(is.na(data_exp5), arr.ind = T)


data_long <- na.locf(data_long)
data_exp5 <- na.locf(data_exp5)
write.csv(data_exp5, "Data_exp5.csv")
```





# Plots 3D!!!

```{r}
library(rgl)
#cbind(x,y,z)
plot3d(data_exp5_named$person_1$repetion_1, type = 'p', col = heat.colors(1000), lwd = 2, xlab = 'x', ylab = 'y', zlab = 'z')

lines3d(x = data_long$X, y = data_long$Y, z = data_long$Z, col = data_long$Experiment)

summary(data_exp5)

```


# Standardization

```{r}
data_wide[colnames] <- scale(data_wide[colnames])

#str(data_wide[,-c(1,2)])
pca <- prcomp(x = data_wide[,-c(1,2)], scale. = T, center = T)
summary(pca)

plot(pca$x, col = data_wide$persons)
```
# PCA - test

# Machine learning

Methods

```{r}
library(ggplot2)

w <- sort(rep(1:10,10))
svd <- svd(data_wide[3:302])
PC <- as.matrix(data_wide[3:302]) %*% svd$v
ggplot(data = as.data.frame(PC), aes(x = V1, y = V2, col = as.factor(w))) + geom_point()
svd$d
```














# Cross-Validation KNN (1 Neighbour) & Logistic Regression
*Korrekt brug af McNemar? Binomial eller med continuity correction * \
*Konfidens intervaller - Beta funktion?*

```{r}
library(class)
library(nnet)


data_CV <- data_wide

N <- nrow(data_CV)
s <- sample(N)
K_fold <- 10

K <- c(1:20)

accuracy <- c()
random_index <- split(sample(c(1:N),N), c(1:K_fold))
 
for (i in c(1:K_fold)){
  print(i)
  f <- c(1:K_fold)[-i]
  train_index <- Reduce(c,random_index[f])
  test_index <- Reduce(c,random_index[i])

  train_set <- data_CV[train_index,]
  test_set <- data_CV[test_index,]
  
  pred_KNN <- knn(train_set[,-c(1,2)], test_set[,-c(1,2)], train_set$persons, k = 1)
  acc_KNN <- pred_KNN == test_set$persons
  
  LogReg <- multinom(data = train_set[,-2], formula = persons ~ ., MaxNWts = 10000)
  pred_LogReg <- predict(LogReg, test_set[,-c(1,2)])
  acc_LogReg <- pred_LogReg == test_set$persons

  
  accuracy <- rbind(accuracy, cbind(acc_KNN, acc_LogReg))

  
}
accuracy <- as.data.frame(accuracy)
apply(accuracy,2,mean)

n_11 <- sum(accuracy$acc_KNN == T & accuracy$acc_LogReg == T)
n_12 <- sum(accuracy$acc_KNN == T & accuracy$acc_LogReg == F)
n_21 <- sum(accuracy$acc_KNN == F & accuracy$acc_LogReg == T)
n_22 <- sum(accuracy$acc_KNN == F & accuracy$acc_LogReg == F)
contingency <- matrix(c(n_11, n_21, n_12, n_22),nrow = 2)

t <- mcnemar.test(contingency, correct = T)
CI_KNN <- DescTools::BinomCI(sum(accuracy$acc_KNN), 100, method = "jeffrey")
CI_LogReg <- DescTools::BinomCI(sum(accuracy$acc_LogReg), 100, method = "jeffrey")
CI_LogReg
CI_KNN
2* pbinom(max(n_12,n_21) ,s , 1/2)


```


# Punkt 2 - Statistik
Test om der er signifikant effekt af 'experiment' på de resulterende kurver.


Beregner mean-curve for hvert eksperiment.
```{r}
mean_curves <- c()
for (i in 1:16){
  for (j in 1:100){
    
    mean_point <- apply(subset(subset(data_long, Experiment == i), Time == j)[,c(5:7)], 2, mean)
    mean_curves <- rbind(mean_curves, c(i,j,mean_point))
    
  }
  
  
  
}

mean_curves <- as.data.frame(mean_curves)

library(rgl)
#cbind(x,y,z)
plot3d(mean_curves$X, mean_curves$Y, mean_curves$Z, type = 'p', col = mean_curves$V1, lwd = 2, xlab = 'x', ylab = 'y', zlab = 'z')
  
```


Mange one sample t-test, hvor længden imellem hvert punkt i hvert eksperiment sammenlignes.
Nul-hypotese: den gennemsnitlige afstande imellem punkterne i to kurver er 0.
Resultatet giver en dataframe rækker svarene til sammenligning af samtlige kombinationer af de 16 eksperimenter.
Konfidens intervaller. \
*One sample t-test med afstand i mellem punkter? *
*ANOVA - Forskel i mean af X, Y og Z eksperimenterne imellem*


```{r}
names(mean_curves) <- c("Experiment", "Time", "X", "Y", "Z")
combinations <- combn(1:16, 2)
n <- ncol(combinations)
dist_df <- c()
for (i in 1:n){
  curve1 <- subset(mean_curves, Experiment == combinations[1,i])[,c(3:5)]
  curve2 <- subset(mean_curves, Experiment == combinations[2,i])[,c(3:5)]
  distance <- c(combinations[1,i], combinations[2,i], sqrt(apply((curve1 - curve2)^2, 1, sum)))
  dist_df <- rbind(dist_df, distance)
}


dist_df <- as.data.frame(dist_df)

p_vals <- c()
for (i in 1:nrow(dist_df)){
  test <- t.test(dist_df[i, -c(1,2)])
  p_vals <- rbind(p_vals, c(paste0(dist_df[i,1],"-", dist_df[i,2]), test$conf.int[1], test$conf.int[2], test$p.value))
  
}

test$conf.int
p_vals <- as.data.frame(p_vals)
names(p_vals) <- c("Experiments","Lower", "Upper", "P-value")

p_vals$`P-value` <- as.double(levels(p_vals$`P-value`))
p_vals["Adjusted P-values"] <- p.adjust(p_vals$`P-value`, method = "hochberg")
plot(sort(p_vals$`Adjusted P-values`))
```

# ANOVA

```{r}

par(mfrow = c(1,3))
boxplot(data_long$X ~ data_long$Experiment)
boxplot(data_long$Y ~ data_long$Experiment)
boxplot(data_long$Z ~ data_long$Experiment)


model_anova <- aov(data = data_long, formula = X ~ Experiment )
summary(model_anova)
summary.lm(model_anova)

?pairwise.t.test

TukeyHSD(model_anova)

```


